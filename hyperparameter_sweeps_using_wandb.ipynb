{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter-sweeps-using-wandb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6RQmcBdDGLoNQ/qbqW8vB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/effective-ml-mini-projects/blob/main/hyperparameter_sweeps_using_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-uLCK23-KIs"
      },
      "source": [
        "# How to do a Hyperparameter Sweep in Weights and Biases\n",
        "\n",
        "A hyperparameter sweep is used when we want to do hyperparameter tuning of our machine learning model. Weights and Biases allows uses to do sweeps fairly easily and creates some beautiful graphs to see how well our model did after training it with different sets of hyperparameters.\n",
        "\n",
        "# An Overview of Sweeps\n",
        "\n",
        "There a 3 steps to running a sweep with Weights and Biases:\n",
        "\n",
        "1. **Define the sweep:** create a dictionary or YAML file that specifies the parameters to search through, the search strategy, the optimization strategy, etc.\n",
        "\n",
        "2. **Initialize the sweep:** initialize the sweep and pass the dictionary of sweep configurations with: `sweep_id = wandb.sweep(sweep_config)`.\n",
        "\n",
        "3. **Run the sweep agent:** call `wandb.agent(sweep_id, function=train)`, where `function` defines the model architecture and trains it.\n",
        "\n",
        "If you decide the create a YAML file for your sweep, it should look something like this for a **deep learning** model:\n",
        "\n",
        "    # sweep.yaml\n",
        "    program: train.py\n",
        "    method: random\n",
        "    metric:\n",
        "     name: val_loss\n",
        "     goal: minimize\n",
        "    parameters:\n",
        "     learning-rate:\n",
        "       min: 0.00001\n",
        "       max: 0.1\n",
        "     optimizer:\n",
        "       values: [\"adam\", \"sgd\"]\n",
        "     hidden_layer_size:\n",
        "       values: [96, 128, 148]\n",
        "     epochs:\n",
        "       value: 27\n",
        "    early_terminate:\n",
        "       type: hyperband\n",
        "       s: 2\n",
        "       eta: 3\n",
        "       max_iter: 27\n",
        "\n",
        "And if you use a python dictionary, it should look like this for an xgboost model:\n",
        "\n",
        "    sweep_config = {\n",
        "        \"method\": \"random\", # try grid or random\n",
        "        \"metric\": {\n",
        "          \"name\": \"accuracy\",\n",
        "          \"goal\": \"maximize\"   \n",
        "        },\n",
        "        \"parameters\": {\n",
        "            \"booster\": {\n",
        "                \"values\": [\"gbtree\",\"gblinear\"]\n",
        "            },\n",
        "            \"max_depth\": {\n",
        "                \"values\": [3, 6, 9, 12]\n",
        "            },\n",
        "            \"learning_rate\": {\n",
        "                \"values\": [0.1, 0.05, 0.2]\n",
        "            },\n",
        "            \"subsample\": {\n",
        "                \"values\": [1, 0.5, 0.3]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "If you want to run a sweep from the command-line, you can run the following commands:\n",
        "\n",
        "1. **Setup a new sweep:** `wandb sweep sweep.yaml` which creates your sweep, and returns both a unique identifier (SWEEP_ID) and a URL to track all your runs.\n",
        "\n",
        "2. **Launch the sweep:** `wandb agent SWEEP_ID`, this will start the hyperparameter sweep and return the URL where you can track the sweep's progress. You can also launch multiple agents (GPUs / CPUs) concurrently. Each of these agents will fetch parameters from the W&B server and use them to train the next model.\n",
        "\n",
        "Documentation on sweeps can be found here: https://docs.wandb.ai/guides/sweeps/quickstart\n",
        "\n",
        "**Tips:** \n",
        "\n",
        "1. You are probably going to end up doing more than one hyperparameter sweep, so start out broad and then hone in on the hyperparameter space with the best performance for your next sweeps.\n",
        "\n",
        "2. Try to use log ditributed sweeps (especially for batch size, learning rate, and hidden layer size). Instead of doing sweeps uniformly between every value in 1 to 1000, you can try every order of magnitude (1, 10, 100, 1000). For example, `q_log_uniform` will try different orders of magnitude with equal probability.\n",
        "\n",
        "Now, let's get started with code!\n",
        "\n",
        "## Setup\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E9tAzvxY6cKu",
        "outputId": "22fbb2d0-113f-4032-8c68-7e343ca2cefb"
      },
      "source": [
        "!pip install wandb --upgrade\n",
        "\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 34.4 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 143 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 163 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 194 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 204 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 215 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 225 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 235 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 245 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 256 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 266 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 276 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 286 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 296 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 307 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 317 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 327 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 337 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 348 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 358 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 368 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 378 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 389 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 399 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 409 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 419 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 430 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 440 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 450 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 460 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 471 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 481 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 491 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 501 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 512 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 522 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 532 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 542 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 552 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 563 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 573 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 583 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 593 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 604 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 614 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 624 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 634 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 645 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 655 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 665 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 675 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 686 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 696 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 706 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 716 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 727 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 737 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 747 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 757 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 768 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 778 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 788 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 798 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 808 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 819 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 829 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 839 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 849 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 860 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 870 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 880 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 890 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 901 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 911 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 921 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 931 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 942 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 952 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 962 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 972 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 983 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 993 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.4 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=f7f120447558a9ca8a7cdf421ff96b883521b21a0864e8ec318dd7fe6c261f2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c193af086847df8df831f03589fd14f36f2a6afbf9870fa9236c16b70b5daa82\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSFtaCRrJoW0"
      },
      "source": [
        "# Step 1. Define the Sweep\n",
        "\n",
        "Fundamentally, a Sweep combines a strategy for trying out a bunch of hyperparameter values with the code that evaluates them. We configure it with different hyperparameters and a method like bayesian optimization (`bayes`) or `random` search.\n",
        "\n",
        "Usually we choose either random search or bayesian search. Bayesian is great, but it does not do so well when you have a ton of hyperparameters (scales poorly as a function of number of hyperparameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOGh-eOKJhBB"
      },
      "source": [
        "import math\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "    'optimizer': {\n",
        "        'values': ['adam', 'sgd']\n",
        "    },\n",
        "    'fc_layer_size': {\n",
        "        'values': [128, 256, 512]\n",
        "    },\n",
        "    'dropout': {\n",
        "        'values': [0.3, 0.4, 0.5]\n",
        "    },\n",
        "    'epochs': {\n",
        "        'value': 1\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        # a flat distribution between 0 and 0.1\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0,\n",
        "        'max': 0.1\n",
        "    },\n",
        "    'batch_size': {\n",
        "        # integers between 32 and 256\n",
        "        # with evenly-distributed logarithms\n",
        "        'distribution': 'q_log_uniform', # Quantized log uniform. Returns round(X, q) \n",
        "                                         # allows you to try every order of magnitude uniformly\n",
        "        'q': 1,\n",
        "        'min': math.log(32),\n",
        "        'max': math.log(256),\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# We can also include hyperband for early stopping"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znO2-TyhX0MB",
        "outputId": "c5450c8a-0482-4b83-aa98-c46ea6d39c69"
      },
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
            " 'parameters': {'batch_size': {'distribution': 'q_log_uniform',\n",
            "                               'max': 5.545177444479562,\n",
            "                               'min': 3.4657359027997265,\n",
            "                               'q': 1},\n",
            "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
            "                'epochs': {'value': 1},\n",
            "                'fc_layer_size': {'values': [128, 256, 512]},\n",
            "                'learning_rate': {'distribution': 'uniform',\n",
            "                                  'max': 0.1,\n",
            "                                  'min': 0},\n",
            "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn44HMDPWPa3"
      },
      "source": [
        "# Step 2. Initialize the Sweep\n",
        "\n",
        "Weights and Biases has something called the Sweep Controller that handles the Sweep and issues a new set of instructions describing a new run to execute locally on our machines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvyQHgXSPk5B",
        "outputId": "18de5c16-8d7d-41e3-bbc3-499a866406bc"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='pytorch-sweeps-demo')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 5rmgndiy\n",
            "Sweep URL: https://wandb.ai/jacquesthibs/pytorch-sweeps-demo/sweeps/5rmgndiy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcq5Xqr4XJ4I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}